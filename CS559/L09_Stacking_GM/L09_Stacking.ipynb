{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36c85b4b",
   "metadata": {},
   "source": [
    "# <center> Lecture 9: Ensemble Methods II - Stacking </center>\n",
    "\n",
    "We have a classification problem of identifying the wine class label based on its chemical analysis of wine grown in the same region. \n",
    "We are going to use emsemble methods (Bagging, RandomForest, Boosting techniques, and stacking technique) to improve the model. \n",
    "You can visit here - https://archive.ics.uci.edu/ml/datasets/wine - for the details on data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3046467",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "Recall Ensemble Method I lecture, we learned that we can overcome the limitations the decision tree (DT) has by creating $n$-trees either by using subsamples or subtrees:\n",
    "\n",
    "- reduce variance (Random Forest) \n",
    "- reduce bias (boosting)\n",
    "\n",
    "Random Forest:\n",
    "- Pros – robust to outliers, non-linear data, runs efficiently, and prevents over-fitting unlike DT\n",
    "- Cons – high bias for categorical features, slow training process, not sufficient for linear methods with a lot of sparse features\n",
    "\n",
    "Boosting:\n",
    "- Pros – easy to handle, many technique choices, prevents over-fitting, better results\n",
    "- Cons – sensitive to outliers, often ignores variance issues, expensive computational cost\n",
    "\n",
    "Question $-$ Is it possible make a model that **learns from different learnings?**\n",
    "- In RF, we learn by aggregating learnings from different subsamples\n",
    "- In Boosting, we learn by updating previous learnings. \n",
    "- They are both tree-based. What is going to happend if we aggregate learns from different bases of models. For example, $h(h_{svm},h_{LR},h_{DT})=?$\n",
    "    - this technique is called **stacking**. \n",
    "\n",
    "## Metalearning\n",
    "**Meta learning** is\n",
    "- Also known as ***learning to learn***\n",
    "- Used to improve the results and performance of a learning algorithm by changing some aspects of the learning algorithms based on experiment results\n",
    "\n",
    "**Meta learning** is useful for\n",
    "- large training datasets\n",
    "- when high computational costs are required due to many trials/experiments during the training phase\n",
    "- when it is hard to find the best model which performs the best for a particular dataset\n",
    "\n",
    "In last 5 years, meta learning accelerated growing, thanks to deep learning and advanced machine learning researches. \n",
    "\n",
    "A meta learning algorithm is **trained with outputs** and metadata of machine learning algorithms. \n",
    "Its skills gets tested before making the final predictions and tasks we can do such as \n",
    "- Observations of different ML models’ performances\n",
    "- Learning from meta data\n",
    "- Faster learning process for a new task. \n",
    "\n",
    "With an annotated data set, \n",
    "1. Various ML models are built\n",
    "2. Use meta training process is used to improve the performance of these models\n",
    "3. Build a new model from examples learned from the previous training process\n",
    "\n",
    "<img src=\"metalearning_1.png\" width=\"500\">\n",
    "\n",
    "Four different approaches: \n",
    "- Metric Learning – learning a metric space for predictions\n",
    "- Model-Agnostic Meta Learning (MAML) – a general optimization and task-agnostic algorithm to train the parameters of a model for faster learning with small number of updates, e.g., neural network\n",
    "- Recurrent Neural Networks (RNNs) – a type of artificial neural networks frequently applied for time series, natural language process, etc. \n",
    "- **Stacking/stacked generalization** – a subfield of ensemble learning used in meta learning models. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fef07ed",
   "metadata": {},
   "source": [
    "## Stacking\n",
    "\n",
    "- Stacking is used \n",
    "    - To learn the best combination of predictions from multiple ML algorithms\n",
    "    - To optimize the prediction than using a single ML algorithm\n",
    "- With a given data set, \n",
    "    - We can use many different ML algorithms that are suitable for the data set. \n",
    "    - Considering advantages and disadvantages of trained models, how do we choose the best one?\n",
    "- Why not bagging? \n",
    "    - Bagging uses the samples of the training dataset. \n",
    "    - Different models are used to fit on the same training dataset. \n",
    "- Why not boosting?\n",
    "    - Boosting uses a sequence of models that corrects the prediction from the previous model by updating the learner (a weak learner to a strong learner)\n",
    "- Use a single model to learn the best combination of predictions from the contributed models  \n",
    "\n",
    "### Models\n",
    "<img src=\"stacking_01.png\" width=\"500\">\n",
    "\n",
    "<u>Level-0 Models</u>\n",
    "- individual ML algorithms are used to fit on training data\n",
    "- Also called *Base-Models*\n",
    "- Base models are complex and diverse – it is good to use wide ranges of models that make different assumptions and conditions to solve the problem. \n",
    "    - For regression – linear regression, decision trees, neural networks, random forest, etc. \n",
    "    - For classification – logistic regression, SVM, KNN, …. \n",
    "\n",
    "<u>Level-1 Model</u>\n",
    "- A model that learns the combination from the predictions made by models on out-of-sample data (can considered as a test set). \n",
    "- Also called *Meta-Model*\n",
    "- A meta model – keep it simple to provide a smooth interpretation of the predictions made from base models. Having a linear model is highly recommended. \n",
    "    - For regression – linear regression\n",
    "    - For classification – logistic regression or SVM\n",
    "\n",
    "#### Stacking base models to a meta model\n",
    "The meta model $H=\\{h_1,\\dots,h_N\\}$ where $h_i$ is an individual base models:\n",
    "$$ \\sum_{i=1}^Nw_ih_i(x_i,y_i)$$\n",
    "To make the final prediction better, we can\n",
    "- Include inputs to the base models to have the best combined predictions.\n",
    "<img src=\"stacking_02.png\" width=\"400\"/>\n",
    "- Use k-fold CV for base models and aggregate them.  \n",
    "<img src=\"stacking_03.png\" width=\"400\"/> \n",
    "- Increase the levels.\n",
    "<img src=\"stacking_04.png\" width=\"600\"/> \n",
    "\n",
    "### Algorithm\n",
    "1. Train Data $D=\\{x_i,y_i\\}_{i=1}^m$\n",
    "1. Step 1: build $N$ base models $h_0=\\{h_1,h_2,\\dots,h_N\\}$\n",
    "1. for $i=1$ to N do\n",
    "    1. build $h_i$ based on $D$\n",
    "1. end\n",
    "1. Step 2: construct new data set of predictions\n",
    "1. for $j=1$ to $m$ do\n",
    "    1. $D_h=\\{x_j',y_j\\}$ where $x_i'=\\{h_1(x_j),\\dots,h_N(x_j)\\}$\n",
    "1. end\n",
    "1. Step 3: build a meta model\n",
    "1. build $H$ based on $D_h$\n",
    "1. return $H$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "343a12e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cf8c4f",
   "metadata": {},
   "source": [
    "## 1. Train data\n",
    "We create a binary classification data set (1000 by 20) using `make_classification`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad7dfa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data',header=None)\n",
    "df_wine.columns = ['Class label','Alcohol','Malic acid','Ash','Alcalinity of ash','Magnesium','Total phenols',\n",
    "                    'Flavanoids','Nonflavanoid phenols','Proanthocyanins','Color intensity','Hue','OD280/OD315 of diluted wines','Proline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f87478b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df_wine['Class label']\n",
    "X=df_wine.drop('Class label',axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=1,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac165e72",
   "metadata": {},
   "source": [
    "## 2. Base Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c675d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    models = dict()\n",
    "    models['lr'] = LogisticRegression()\n",
    "    models['knn'] = KNeighborsClassifier()\n",
    "    models['DT'] = DecisionTreeClassifier()\n",
    "    models['svm'] = SVC()\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5671ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "835bf357",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21b390e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">lr 0.946 (0.065)\n",
      ">knn 0.666 (0.119)\n",
      ">DT 0.896 (0.086)\n",
      ">svm 0.717 (0.117)\n"
     ]
    }
   ],
   "source": [
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, X_train, y_train)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3306a5aa",
   "metadata": {},
   "source": [
    "The train model with logistic regression is significantly better than other classifiers indicating that the data is a linear-data and therefore, it is not necessary to do staking. However, let's observe how stacking can improve the classification if we do not include the logistic regression. Any linear models can be used for level 1 mdoel. \n",
    "\n",
    "In level 1 model, I used logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "352b3ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "    # define the base models\n",
    "    level0 = list()\n",
    "    #level0.append(('lr', LogisticRegression()))\n",
    "    level0.append(('knn', KNeighborsClassifier()))\n",
    "    level0.append(('DT', DecisionTreeClassifier()))\n",
    "    level0.append(('svm', SVC()))\n",
    "    # define meta learner model\n",
    "    level1 = LogisticRegression()\n",
    "    # define the stacking ensemble\n",
    "    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d360ba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    models = dict()\n",
    "    models['lr'] = LogisticRegression()\n",
    "    models['knn'] = KNeighborsClassifier()\n",
    "    models['DT'] = DecisionTreeClassifier()\n",
    "    models['svm'] = SVC()\n",
    "    models['stacking'] = get_stacking()\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f25fa50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28469186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">lr 0.950 (0.055)\n",
      ">knn 0.710 (0.094)\n",
      ">DT 0.891 (0.089)\n",
      ">svm 0.687 (0.096)\n",
      ">stacking 0.904 (0.073)\n"
     ]
    }
   ],
   "source": [
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36356e53",
   "metadata": {},
   "source": [
    "Note that the accuracy with stacking is better than KNN, DT, and SVM but still logistic regression resulted better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d658dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df1xUdb4/8NcwgwqMIAgkNKOCKAoIY84YZYmuP0PFzasB+YtrybLZj7u5re3VVsy9PizzXtvYbS7Vomwhud2M/EWpSV+9mUjmT1KhEPmR/FBBFIxh+Nw//DqKDDAIhwHP6/l4+Hg4cz7nnPc5c5jXnM/5pRBCCBARkWw52LsAIiKyLwYBEZHMMQiIiGSOQUBEJHMMAiIimWMQEBHJHINAxuLi4rBy5UqrwxISErBmzZouruim8ePH4/3335dk2hcuXIBarYbZbAYAlJWVYdy4cejbty+WLVuGtWvX4tlnn5Vk3h2VmJiI+fPnWx2WlZUFjUbTxRXZV2vr425SblP3AwZBN3Tw4EE8+uijcHNzg4eHB8aOHYsjR44AADZt2oTHHntM8hqMRiNee+01SaZdX1+PxMREDB06FC4uLhg8eDAWL16M8+fPSzK/Ow0cOBDXrl2DUqkEACQnJ8PT0xNXr17Fhg0b8O///u/8wrBRV22LJD0GQTdz9epVzJgxAy+88AIuX76MkpISrFq1Cr1797Z3aZ1mzpw5+Pzzz5GWlobq6mocP34co0ePxr59+7q8lsLCQgQFBUGhUHRoOkIINDY2dlJVRF2LQdDNnDt3DgAQGxsLpVIJJycnTJkyBaGhofjhhx+QkJCAQ4cOQa1Wo1+/fgCAnTt3YtSoUXB1dYVWq0ViYmKTad7aw+jXrx+0Wi02bdrUbL41NTWYMGECXnzxRQghmnQb3ep22LBhA7y9veHj44OUlBTLuJcuXcLMmTPh6uoKg8GAlStXtvhLce/evdizZw8yMjJgMBigUqng5uaGpUuX4plnnmnW/scff8SvfvUr9O/fH56enpg3bx6qqqosw9944w08+OCD6Nu3LwIDAy1hkp2dDb1eD1dXVzzwwAN4+eWXAQDnz5+HQqFAQ0MD4uLisHnzZrz55ptQq9XYu3dvs+6Gb7/91rLuwsLCkJWVZRk2fvx4rFixAmPHjoWzszN++umnZvWvW7cOQ4YMQd++fREUFIRt27ZZht36Rf373/8e7u7u8PPzw+7duy3DCwoKEBERgb59+2Ly5MmorKy0uk7vtHbtWnh6emLw4MH46KOPLO+3to3cuHED8+fPR//+/dGvXz8YDAaUlZUBAKqrq/HMM8/Ax8cHDz74IFauXAmz2dzitni38ePHY+XKlXj00UehVqsxc+ZMXLp0CfPmzbNsL3fuCX7zzTcwGAxwc3ODwWDAN998Y/P6aO2zulN+fj4iIiLg5uYGT09PREdHt7le73uCupXq6mrh4eEhFi5cKHbt2iUuX77cZHhKSooYO3Zsk/f2798vTpw4Icxmszh+/Ljw9vYW27ZtE0IIUVhYKNRqtUhLSxP19fWisrJSfP/990IIIRYtWiRWrFghKisrhcFgECtWrLBM89awW9NXKpXitddeE/X19WLnzp3CycnJUlt0dLSIjo4W169fF6dPnxYajaZZjbcsX75cjBs3rtV1EBERId577z0hhBB5eXniyy+/FDdu3BDl5eXi8ccfFy+99JIQQogzZ84IjUYjSkpKhBBCFBQUiPz8fCGEEOHh4SI1NVUIIURNTY04dOiQpQ0AYTKZmi2nEEKsWrVKzJs3TwghRHFxsfDw8BA7d+4UZrNZfPnll8LDw0OUl5db6tRqteLUqVPCZDKJ+vr6ZsuydetWUVJSIsxms0hPTxfOzs6itLTU8lmqVCqRnJwsGhoaxN/+9jfh4+MjGhsbLcvwu9/9Tty4cUN8/fXXQq1WW2q7263P6Fb7rKws4ezsLM6cOWMZ3tI2YjQaxYwZM8T169dFQ0ODyMnJEdXV1UIIIWbNmiXi4+PFtWvXRFlZmTAYDMJoNFrqb+lzvvOzHDJkiMjPzxdVVVVixIgRYujQoWLPnj3CZDKJBQsWiLi4OCGEEJcuXRL9+vUTqampwmQyibS0NNGvXz9RWVnZ5vqw5bO6tU3FxMSIP//5z8JsNou6ujpx4MCBVpdBDrhH0M24urri4MGDUCgUWLJkCby8vBAVFWX5hWbN+PHjMXLkSDg4OCA0NBSxsbH4+uuvAQAfffQRJk2ahNjYWDg6OqJ///7Q6XSWcUtLSxEREYG5c+fiz3/+c4vzcHR0xJ/+9Cc4OjoiMjISarUaZ8+ehdlsxv/8z/9g9erVcHZ2RlBQEBYtWtTidC5dugQfHx+b10dAQAAmT56M3r17w8vLCy+//LJl2ZRKJX755Rfk5ubCZDJh8ODBGDJkiKXe/Px8VFZWQq1WIzw83OZ53vLhhx8iMjISkZGRcHBwwOTJk6HX67Fr1y5Lm7i4OAQHB0OlUsHR0bHZNObOnQtfX184ODggOjoaQ4cORXZ2tmX4oEGDsGTJEiiVSixatAg///wzysrKcOHCBRw5cgRr1qxB7969MW7cOMycObPNmm+1j4iIwPTp07F161YArW8jjo6OuHTpEvLz86FUKjF69Gi4urqirKwMu3fvxsaNG+Hi4gJvb2/87ne/Q3p6ervW47/+679iyJAhcHNzwxNPPIEhQ4Zg0qRJUKlUmDt3Lr7//nsAN/dahg4digULFkClUiE2NhbDhw/H9u3b21wftnxWtzg6OqKwsBClpaXo06cPj3OAXUPd0ogRI7Bp0yYUFxfj1KlTKC0txb/927+12P7w4cOYMGECvLy84ObmBqPRaNltLioqsnw5WrNz507U1dUhISGh1Zr69+8PlUplee3s7Ixr166hoqICDQ0N0Gq1lmF3/t/adH7++edW53Wn8vJyxMTE4MEHH4Srqyvmz59vWbaAgABs3LgRiYmJ8Pb2RkxMDEpLSwEAH3zwAc6dO4fhw4fDYDBgx44dNs/zlsLCQvzzn/9Ev379LP8OHjzYpP7WlhUAUlNTodPpLOOfOnWqSZfGgAEDLP93dnYGAFy7dg2lpaVwd3eHi4uLZfigQYNanZe19rfWR2vbyIIFCzB16lTExMTA19cXf/jDH2AymVBYWAiTyQQfHx9L/b/5zW9QXl7e1qpr4oEHHrD838nJqdnra9euAbj5o+TuZRw0aBBKSkraXB+2fFa3vPnmmxBCYMyYMQgODsbf//73di3P/YhB0M0NHz4ccXFxOHXqFABYPaj59NNPIyoqCkVFRaiurkZCQgLE/7+prFarxY8//tji9JcsWYJp06YhMjIS169fb3d9Xl5eUKlUKC4utrxXVFTUYvtJkyYhOzu7SfvW/PGPf4RCocCJEydw9epVfPjhh5ZlA24u+8GDB1FYWAiFQoHly5cDAIYOHYotW7agvLwcy5cvx5w5c9q9fFqtFgsWLEBVVZXl3/Xr1/Hqq69a2rR2kLmwsBBLlixBUlISLl26hKqqKoSEhDSpvyU+Pj64cuVKk5ovXLjQ6jjW2vv6+gJofRtxdHTEqlWrkJubi2+++QY7duxAamoqtFotevfujcrKSsvyX716FadPn25z2e+Fr68vCgsLm7x34cIFPPjgg22uD1s+q1sGDBiA9957D6Wlpfjv//5vPPfcc8jPz+/UZelpGATdzJkzZ7BhwwbLF2VRURG2bNli6dp44IEHUFxcjPr6ess4NTU18PDwQJ8+fZCdnY20tDTLsHnz5mHv3r3YunUrGhoacOnSJRw7dqzJPJOSkhAYGIgZM2agrq6uXfUqlUrMnj0biYmJqK2txZkzZ5Camtpi+0mTJmHy5Ml48skn8d1336GhoQE1NTUwGo1Wf5nV1NRYDkaWlJRg/fr1lmFnz57FV199hV9++QV9+vSBk5OT5bTQDz/8EBUVFXBwcLAcyLw1zFbz58/H9u3b8cUXX8BsNuPGjRvIysqyOcSuX78OhUIBLy8vAEBKSool0NsyaNAg6PV6rFq1CvX19Th48CC2b9/e5ni32h84cAA7duzA3LlzAbS+jezfvx8nT56E2WyGq6srHB0doVQq4ePjgylTpmDZsmW4evUqGhsb8eOPP1q6lKxtix0RGRmJc+fOIS0tDQ0NDfj444+Rm5uLGTNmtLk+2vNZ/fOf/7S87+7uDoVC0e5t437DIOhm+vbti8OHD+Phhx+Gi4sLwsPDERISgg0bNgAAfvWrXyE4OBgDBgyAp6cnAOBvf/sb/vSnP6Fv3754/fXX8dRTT1mmN3DgQOzatQsbNmyAh4cHdDodjh8/3mSeCoUCycnJ0Gq1mDVrFm7cuNGumpOSklBdXY0BAwZgwYIFiI2NbfV0108++QSRkZGIjo6Gm5sbQkJCkJOTg0mTJjVru2rVKhw9ehRubm6YPn06Zs+ebRn2yy+/4NVXX4WnpycGDBiA8vJyrF27FgCQmZmJ4OBgqNVqvPTSS0hPT0efPn3atVxarRYZGRlYu3YtvLy8oNVqsX79eptPEw0KCsKyZcvwyCOP4IEHHsDJkycxduxYm+eflpaGw4cPw8PDA6tXr8bChQtbbT9gwAC4u7vD19cX8+bNg9FoxPDhwwG0vo1cvHgRc+bMgaurK0aMGIGIiAjLmVOpqamor69HUFAQ3N3dMWfOHEt3i7VtsSP69++PHTt2YMOGDejfvz/efPNN7NixwzLt1tZHez6rI0eO4OGHH4ZarUZUVBTefvtt+Pn5dbj+nkwhbNlPJWqH5cuX4+LFi9i8ebO9SyEiG3CPgDrszJkzOHHiBIQQyM7OxgcffIAnn3zS3mURkY1UbTchal1NTQ1iY2NRWloKb29vLFu2DLNmzbJ3WURkI3YNERHJHLuGiIhkrsd1Dd26jwoREdnu/PnzLd6vqscFweDBg5GTk2PvMoiIehS9Xt/iMHYNERHJHIOAiEjmGARERDLHICAikjkGARGRzEkWBIsXL4a3tzdCQkKsDhdC4MUXX0RAQABCQ0Nx9OhRqUohIqJWSBYEcXFxyMzMbHH47t27kZeXh7y8PCQnJ+O3v/2tVKUQEVErJAuCcePGwcPDo8XhGRkZWLhwIRQKBcLDw1FVVdWuJ1cREVHnsNsFZSUlJU0e86fRaFBSUmL1ebbJyclITk4GAFRUVHR43h4eHrhy5UqHp9MR7u7uuHz5sl1roPbprCdy8fZe95f7YbuwWxBYW+iWVmh8fDzi4+MBtH51nK2uXLli9z/Gzn7MH0nPlm1GoVDYfduirnU/bBd2O2tIo9E0ebZtcXGx5fmqRETUdewWBFFRUUhNTYUQAt9++y3c3NysdgsREZG0JOsaio2NRVZWFiorK6HRaLB69WqYTCYAQEJCAiIjI7Fr1y4EBATA2dkZKSkpUpVCREStkCwItmzZ0upwhUKBv/71r1LNnqjdOuskgo4c/+FJBN2PHLaLHncbaiKp8CQCskYO2wVvMUFEJHMMAiIimWMQEBHJHIOAiEjmGARERDLHICAikjkGARGRzDEIiIhkjkFwDypqKxCXGYfKukp7l0JE1GEMgntgPGHE0bKjMB432rsUIqIOYxC0U0VtBTLyMyAg8Fn+Z9wrIKIej0HQTsYTRjSKRgBAo2jkXgER9XgMgna4tTdgarx5O21To4l7BUTU48ny7qNilSuQ6Nbu8Yz93dGoVgMOt+8E2Gi6AeP7eqy81L7b1IpVru2ePxGRFGQZBIrVV+/ptrLHP58D05WzTd4zOShwbJAeeOGT9tWgUEAktrsEIqJOJ8sguFefRLXvy56IqCfgMQIiIpljEBARyRyDgIhI5hgEREQyxyAgIpI5BgERkcwxCIiIZI5BQEQkcwwCIiIJ9YTnlzAIiIgk1BOeXyJpEGRmZiIwMBABAQFYt25ds+FXrlzBk08+idDQUIwZMwanTp2Sshwioi7VU55fIlkQmM1mLF26FLt370Zubi62bNmC3NzcJm3Wrl0LnU6HEydOIDU1FS+99JJU5RARdbme8vwSyYIgOzsbAQEB8Pf3R69evRATE4OMjIwmbXJzczFx4kQAwPDhw3H+/HmUlZVJVRIRUZfpSc8vkSwISkpKoNVqLa81Gg1KSkqatAkLC8Onn34K4GZwFBYWori4uNm0kpOTodfrodfrUVFRIVXJRB3SEw4KUte5c2/glu66VyBZEFi7379CoWjy+tVXX8WVK1eg0+nwzjvvYNSoUVCpmt8ZOz4+Hjk5OcjJyYGXl5dUJRN1SE84KEhd53j5ccvewC2mRhOOlR+zU0Utk+x5BBqNBkVFRZbXxcXF8PX1bdLG1dUVKSkpAG4Gh5+fH/z8/KQqiUgydx8UTAhLgKeTp73LIjvqSc8vkWyPwGAwIC8vDwUFBaivr0d6ejqioqKatKmqqkJ9fT0A4P3338e4cePg6spHOFLP01MOChJZI9kegUqlQlJSEqZOnQqz2YzFixcjODgYRuPNP5CEhAT88MMPWLhwIZRKJYKCgvDBBx9IVU4zd3dTdTV3d3e7zt9WnbWe7uXRoF3tXp9lXaF0QIbGFyaHm7+rTI0mfPbDFiTs2QBPc2MbY1upgbqVe90uOr0GCSlET/gLvYNer0dOTo69y7j5zOGeteokc7+si3tdjjXfrsG2vG1N+oMdHRwxe+hsrAxf2SU1kHS6w2fSGTW09t3JK4uJOqgnHRQksoYPryfqoJ50UJDIGu4REBHJHIOAiEjmGARERDLHICAikjkGARGRzDEIiIhkjkFARCRzDAIiIpljEBARyRyDgIhI5hgEREQyx3sNERG14X6/bT2DgIioFZ1xC+rucCvr1rBriIhI5hgEREQyxyAgIpI5HiOwwtYDQ2216859gmTd/X5QsLPI6VnWcsAgsIIbpzzJ4aBgZ7FlGeWyLu4H7BoiIpI5BgERkcwxCIiIZI5BQEQkcwwCIiKZYxAQEcmcpEGQmZmJwMBABAQEYN26dc2GV1dXY+bMmQgLC0NwcDBSUlKkLIeIiKyQLAjMZjOWLl2K3bt3Izc3F1u2bEFubm6TNn/9618RFBSE48ePIysrC8uWLUN9fb1UJRERkRWSBUF2djYCAgLg7++PXr16ISYmBhkZGU3aKBQK1NTUQAiBa9euwcPDAyoVr3EjIupKkgVBSUkJtFqt5bVGo0FJSUmTNs8//zx++OEH+Pr6YuTIkXj77bfh4NC8pOTkZOj1euj1elRUVEhVMhGRLEkWBNYuLb/7/iRffPEFdDodSktLcezYMTz//PO4evVqs/Hi4+ORk5ODnJwceHl5SVUyEZEsSRYEGo0GRUVFltfFxcXw9fVt0iYlJQWzZ8+GQqFAQEAA/Pz8cObMGalKIiIiKyQLAoPBgLy8PBQUFKC+vh7p6emIiopq0mbgwIHYt28fAKCsrAxnz56Fv7+/VCUREZEVkh2ZValUSEpKwtSpU2E2m7F48WIEBwfDaDQCABISEvDaa68hLi4OI0eOhBACb7zxBjw9PaUqiYiIrFCIHnafWL1ej5ycHHuXQXfg7YZv47q4jevitu6wLlr77uSVxUREMscgICKSOQYBEZHMMQhkzsPDAwqFokP/AHRofA8PDzuvBSJ54/0cZO7KlSt2P4hl7wfGE8kd9wiIiGSOQUBEJHPsGiKiZjw8PHDlypUOT6cj3X7u7u64fPlyh2uQmq3L2FY7e3bRMgiIqBkeO7KdvddTZ2DXEBGRzDEIiIhkzuYgqKurw9mzZ6WshYiI7MCmINi+fTt0Oh2mTZsGADh27FizW0oTEVHPZFMQJCYmIjs7G/369QMA6HQ6nD9/Xsq6iIioi9gUBCqVCm5ublLXQkREdmBTEISEhCAtLQ1msxl5eXl44YUX8Oijj0pdGxERdQGbguCdd97B6dOn0bt3bzz99NNwc3PDxo0bpa6NiIi6QJsXlJnNZkRFRWHv3r34j//4j66oiYiIulCbewRKpRLOzs6orq7uinqIiKiL2XSLiT59+mDkyJGYPHkyXFxcLO//5S9/kawwIiLqGjYFwfTp0zF9+nSpayEiIjuwKQgWLVqE+vp6nDt3DgAQGBgIR0dHSQsjIqKuYVMQZGVlYdGiRRg8eDCEECgqKsLmzZsxbtw4qesjiYlVrkCifa8REatc7Tp/IrmzKQiWLVuGL7/8EoGBgQCAc+fOITY2Ft99952kxZH0FKuvdug2uhW1FXjl/72CtyLegqeT573VoFBAJN5zCUTUQTZdR2AymSwhAADDhg2DyWSSrCjqOYwnjDhadhTG40Z7l0JE98imINDr9XjmmWeQlZWFrKwsLFmyBKNHj5a6NurmKmorkJGfAQGBz/I/Q2Vdpb1LIqJ7YFMQvPvuuwgODsZf/vIXvP322wgKCoLRyF+Acmc8YUSjaAQANIpG7hUQ9VA2BUFDQwNeeuklfPrpp9i2bRtefPFFmM3mNsfLzMxEYGAgAgICsG7dumbD169fD51OB51Oh5CQECiVyh7xjFK6vTdgarzZRWhqNHGvgKiHUggbjhSGh4dj7969UKvVAIBr165hypQp+Oabb1ocx2w2Y9iwYdizZw80Gg0MBgO2bNmCoKAgq+23b9+O//qv/8JXX33Vai16vR45OTltlUw2UigU93SweM23a7Atb5slCADA0cERs4fOxsrwlV1SQ1frrGfo9oRltfeZZBaJvKNBZ2ntu9Oms4Zu3LhhCQEAUKvVqK2tbXWc7OxsBAQEwN/fHwAQExODjIyMFoNgy5YtiI2NtaUc6gaOlx9vEgLAzb2CY+XH7FSR9HrEF3gn6ejZZJ1SA88m6zI2BYGLiwuOHj2Khx56CACQk5MDJyenVscpKSmBVqu1vNZoNDh8+LDVtrW1tcjMzERSUpLV4cnJyUhOTgYAVFRU2FIySeyTqE/sXQIRdRKbgmDjxo2YO3cufH19oVAoUFpaio8//rjVcaz9mmhp13r79u0YO3YsPDw8rA6Pj49HfHw8gJu7N0RE1HlaPVh85MgRXLx4EQaDAWfOnEF0dDRUKhWmTZsGPz+/Vies0WhQVFRkeV1cXAxfX1+rbdPT09ktRHQfqaitQFxmHE8e6CFaDYLf/OY36NWrFwDg0KFDWLt2LZYuXQp3d3fLL/SWGAwG5OXloaCgAPX19UhPT7f6wPvq6mp8/fXXmDVrVgcWg4i6E15o2LO0GgRms9nSXfPxxx8jPj4e//Iv/4I1a9YgPz+/1QmrVCokJSVh6tSpGDFiBJ566ikEBwfDaDQ2uQZh27ZtmDJlSpPbWxNRz8ULDXueVo8RmM1mNDQ0QKVSYd++fZYDtsDNawvaEhkZicjIyCbvJSQkNHkdFxeHuLi4dpRMRN2ZtQsN23tKMXWtVvcIYmNjERERgVmzZsHJyQmPP/44ACA/Px9ubt3kPGMi6jZ4oWHP1OoewYoVKzBx4kT8/PPPmDJliuWsn8bGRrzzzjtdUiAR9Rx37g3cwr2C7q/N00fDw8ObvTds2DBJiiGink2OFxreD2y6joCIyBa80LBnsummc0REdP9iEBARyRy7hqjT7qp5r9zd3e06fyK5YxDIXGfcYbKn3EaaiKxj1xARkcwxCIiIZI5BQEQkcwwCIiKZYxAQEckcg4CISOYYBEREMscgICKSOQYBEZHMMQiIiGSOQUBEJHMMAiIimWMQEBHJHIOAiEjmeBtqIrKKz6mQDwYBETXD51TIC7uGiIhkjkFARCRzkgZBZmYmAgMDERAQgHXr1lltk5WVBZ1Oh+DgYEREREhZDhERWSHZMQKz2YylS5diz5490Gg0MBgMiIqKQlBQkKVNVVUVnnvuOWRmZmLgwIEoLy+XqhwiImqBZHsE2dnZCAgIgL+/P3r16oWYmBhkZGQ0aZOWlobZs2dj4MCBAABvb2+pyiEiohZIFgQlJSXQarWW1xqNBiUlJU3anDt3DleuXMH48eMxevRopKamSlUOERG1QLKuIWunjd19XnJDQwO+++477Nu3D3V1dXjkkUcQHh6OYcOGNWmXnJyM5ORkAEBFRYVUJRMRyZJkewQajQZFRUWW18XFxfD19W3WZtq0aXBxcYGnpyfGjRuH48ePN5tWfHw8cnJykJOTAy8vL6lKJiKSJcmCwGAwIC8vDwUFBaivr0d6ejqioqKatJk1axYOHDiAhoYG1NbW4vDhwxgxYoRUJRERkRWSdQ2pVCokJSVh6tSpMJvNWLx4MYKDg2E0GgEACQkJGDFiBKZNm4bQ0FA4ODjg2WefRUhIiFQlERGRFQrRw64B1+v1yMnJsXcZdAfeSoCs4XbRvbT23ckri4mIZI5BQEQkcwwCIiKZYxAQEckcg4CISOYYBEREMscgICKSOQYBEZHMMQiIiGSOQUBEJHOS3WuI7g933zr8XtvxVgNE3ReDgFrFL3Ci+x+7hoiIZI5BQEQkcwwCIiKZYxAQEckcg4CISOYYBEREMscgICKSOQYBEZHMMQiIiGSOQUBEJHMMAiIimWMQEBHJHIOAiEjmGARERDLHICAikjlJgyAzMxOBgYEICAjAunXrmg3PysqCm5sbdDoddDodXn/9dSnLISIiKyR7MI3ZbMbSpUuxZ88eaDQaGAwGREVFISgoqEm7xx9/HDt27JCqDCIiaoNkewTZ2dkICAiAv78/evXqhZiYGGRkZEg1OyIiukeSBUFJSQm0Wq3ltUajQUlJSbN2hw4dQlhYGJ544gmcPn3a6rSSk5Oh1+uh1+tRUVEhVclERLIkWdeQtWfd3v2A84ceegiFhYVQq9XYtWsXfv3rXyMvL6/ZePHx8YiPjwcA6PV6aQomIpIpyfYINBoNioqKLK+Li4vh6+vbpI2rqyvUajUAIDIyEiaTCZWVlVKVREREVkgWBAaDAXl5eSgoKEB9fT3S09MRFRXVpM3Fixctew7Z2dlobGxE//79pSqJiIiskKxrSKVSISkpCVOnToXZbMbixYsRHBwMo9EIAEhISMAnn3yCd999FyqVCk5OTkhPT2/WfURERNJSCGud+d2YXq9HTk6OvcsgojYoFAqrxwrJPlr77uSVxUREMscgICKSOQYBEZHMMQiIiGSOQUBEJHMMAiIimWMQEBHJHIOAiEjmGARERNly5EsAAAcSSURBVDLHICAikjkGARGRzDEIiIhkjkFARCRzDAIiIpmT7HkERHT/svW5IW21422quwcGARG1G7/A7y/sGiIikjkGARGRzDEIiIhkjkFARCRzDAIiIpljEBARyRyDgIhI5hgEREQypxA97MoQT09PDB482N5loKKiAl5eXvYuo1vguriN6+I2rovbusO6OH/+PCorK60O63FB0F3o9Xrk5OTYu4xugeviNq6L27gubuvu64JdQ0REMscgICKSOWViYmKivYvoqUaPHm3vEroNrovbuC5u47q4rTuvCx4jICKSOXYNERHJHIOAiEjmGATtoFar7V1Clzt//jxCQkLsXUa3o1QqodPpEBwcjLCwMPznf/4nGhsb8cUXX0Cn00Gn00GtViMwMBA6nQ4LFy60d8nUARs3bkRtbe09jbtp0yY8//zzzd43Go1ITU3taGmdgk8o6yCz2QylUmnvMqiLOTk54dixYwCA8vJyPP3006iursbq1asxdepUAMD48ePx1ltvQa/X27NU6gQbN27E/Pnz4ezs3GnTTEhI6LRpdRT3CO5BVlYWJkyYgKeffhojR460dzld5qeffsKoUaOwfv16zJ49G9OmTcPQoUPxhz/8wdJGrVZjxYoVCAsLQ3h4OMrKyuxYcdfw9vZGcnIykpKSZPEIx+vXr2P69OkICwtDSEgINm/ejKeeesoyPCsrCzNnzgRwc3tYvnw5Ro8ejUmTJiE7Oxvjx4+Hv78/Pv/8c3stQqvuXr7Vq1ejtLQUEyZMwIQJEwAAv/3tb6HX6xEcHIxVq1ZZxj1y5AgeffRRhIWFYcyYMaipqWky7Z07d+KRRx5BZWUlEhMT8dZbbwG4+aNh+fLlGDNmDIYNG4YDBw4AAGpra/HUU08hNDQU0dHRePjhh6W5ME2QzVxcXIQQQuzfv184OzuLn376yc4VSa+goEAEBweLM2fOCJ1OJ77//nuRkpIi/Pz8RFVVlairqxMDBw4UFy5cEEIIAUB8/vnnQgghXnnlFbFmzRp7li+ZW9vCnfr16ycuXrxoeR0RESGOHDnSlWV1iU8++UQ8++yzltdVVVVCq9WKa9euCSGESEhIEP/4xz+EEDe3h127dgkhhPj1r38tJk+eLOrr68WxY8dEWFhY1xdvA2vLN2jQIFFRUWF579KlS0IIIRoaGkRERIQ4fvy4+OWXX4Sfn5/Izs4WQghRXV0tTCaTSElJEUuXLhWffvqpeOyxx8Tly5eFEEKsWrVKrF+/Xghxc1t5+eWXhRBC7Ny5U0ycOFEIIcT69etFfHy8EEKIkydPCqVSKck2xT2CezRmzBj4+fnZu4wuUVFRgVmzZuHDDz+ETqcDAEycOBFubm7o06cPgoKCUFhYCADo1asXZsyYAeDmedPnz5+3V9ldTshgbwAARo4cib1792L58uU4cOAA3NzcMG3aNGzfvh0NDQ3YuXMnZs2aBeDm9jBt2jTLeBEREXB0dMTIkSO77bZhbfnutnXrVjz00EMYNWoUTp8+jdzcXJw9exY+Pj4wGAwAAFdXV6hUN3vf9+/fjzfeeAM7d+6Eu7u71fnOnj0bQNO/m4MHDyImJgYAEBISgtDQ0M5eXADsGrpnLi4u9i6hy7i5uUGr1eJ///d/Le/17t3b8n+lUomGhgYAgKOjIxQKRbP373c//fQTlEolvL297V2K5IYNG4bvvvsOI0eOxB//+Ee8/vrriI6OxtatW/HVV1/BYDCgb9++AJpuDw4ODpbtxsHBodtuG9aW704FBQV46623sG/fPpw4cQLTp0/HjRs3IISwLOvd/P39UVNTg3PnzrU431vr5s6/m676ccEgoDb16tULn332GVJTU5GWlmbvcrqdiooKJCQk4Pnnn2/xi+B+UlpaCmdnZ8yfPx+///3vcfToUYwfPx5Hjx7Fe++9h+joaHuX2CHWlq9v376W/v6rV6/CxcUFbm5uKCsrw+7duwEAw4cPR2lpKY4cOQIAqKmpsXyhDxo0CJ9++ikWLlyI06dP21zLY489hq1btwIAcnNzcfLkyc5cVAueNUQ2cXFxwY4dOzB58mTMnz/f3uXYXV1dHXQ6HUwmE1QqFRYsWICXX37Z3mV1iZMnT+KVV16Bg4MDHB0d8e6770KpVGLGjBnYtGkTNm/ebO8SO8Ta8h06dAhPPPEEfHx8sH//fowaNQrBwcHw9/fH2LFjAdz8wfTxxx/jhRdeQF1dHZycnLB3717LdAMDA/HRRx9h7ty52L59u021PPfcc1i0aBFCQ0MxatQohIaGWu2q6ijeYoKIqJsym80wmUzo06cPfvzxR0ycOBHnzp1Dr169OnU+3CMgIuqmamtrMWHCBJhMJggh8O6773Z6CADcIyAikj0eLCYikjkGARGRzDEIiIhkjkFARCRzDAIiIpn7PwN6bFQgP4kPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.figure(facecolor='white')\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "\n",
    "pyplot.ylabel('Score')\n",
    "pyplot.title('Stacking Classifier and baset models')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab45debb",
   "metadata": {},
   "source": [
    "## 2. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6022f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(cv=5,\n",
       "                   estimators=[('knn', KNeighborsClassifier()),\n",
       "                               ('DT', DecisionTreeClassifier()),\n",
       "                               ('svm', SVC())],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_stacking()\n",
    "model.fit(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e00f6019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = model.predict(X_test)\n",
    "print('Accuracy',accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69186481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.971830985915493\n",
      "Accuracy 0.8888888888888888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/insukjang/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(X_train,y_train)\n",
    "print('Accuracy',accuracy_score(y_train,LR.predict(X_train)))\n",
    "print('Accuracy',accuracy_score(y_test,LR.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f090e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7323943661971831\n",
      "Accuracy 0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train,y_train)\n",
    "print('Accuracy',accuracy_score(y_train,svc.predict(X_train)))\n",
    "print('Accuracy',accuracy_score(y_test,svc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b908cc93",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Advantage? \n",
    "- Higher model prediction accuracy\n",
    "- A faster, cheaper training process\n",
    "- Builds many generalized models\n",
    "\n",
    "Disadvantage?\n",
    "- Sometimes full understandings of models are not possible\n",
    "- There are many ML algorithms to use…\n",
    "- Overfitting "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
