{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b45e3e05",
   "metadata": {},
   "source": [
    "# <center> CS559 Homework#3: Decision Tree and Ensemble Methods</center>\n",
    "## <center> Due: 11/8/2021 Monday at 11:59 PM</center>\n",
    "\n",
    "\n",
    "In this assignment, you are going to implement four classifiers - **decision tree, random forest, adaboost, and gradient boost**. \n",
    "Then check the performance with `sklearn` built-in algorithms.\n",
    "In this work, splitting into train and test sets is not necessary. \n",
    "\n",
    "The provided data has four columns - three features (a, b, and c) and the target (class). Three features are continuous data and the target is a binary, 0 or 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a67540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52b36fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./F21_CS559_HW3_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce750de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.4202</td>\n",
       "      <td>-4.3507</td>\n",
       "      <td>10.3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.7044</td>\n",
       "      <td>-4.4601</td>\n",
       "      <td>10.6803</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.8075</td>\n",
       "      <td>-4.0894</td>\n",
       "      <td>10.6259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.2771</td>\n",
       "      <td>-4.0349</td>\n",
       "      <td>10.1166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.6447</td>\n",
       "      <td>-3.5968</td>\n",
       "      <td>10.2936</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        a       b        c  class\n",
       "0  9.4202 -4.3507  10.3764      1\n",
       "1  9.7044 -4.4601  10.6803      1\n",
       "2  9.8075 -4.0894  10.6259      1\n",
       "3  9.2771 -4.0349  10.1166      1\n",
       "4  9.6447 -3.5968  10.2936      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b23df4",
   "metadata": {},
   "source": [
    "### Question 1: Decisition Tree Classifier\n",
    "- A simple DT implementation (10 pts.)\n",
    "    - to make the problem simple, implement a decision tree with depth of 3 (the root index is 0).\n",
    "    - calculate the gini index for each attribute and pick the best attribute for each node.\n",
    "    - calculate the accuracy using accuracy score. \n",
    "- Classification using DecistionTreeClassifier (5 pts)\n",
    "- Evaluation (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9065568d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 2500)\n"
     ]
    }
   ],
   "source": [
    "print(range(len(list(df['class']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb708867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorry, I may not able to show the algorithm, but this result might show some ideas.\n",
    "\n",
    "def MyDecisitionTree(data,depth): \n",
    "    \n",
    "    m=data['class'].size\n",
    "    # Count of each class in the current node.\n",
    "    num_parent =[np.sum(y == c) for c in range(len(set(list(data['class']))))]\n",
    "    #count gini impurity\n",
    "    best_gini = 1.0-sum((n/m) **2 for n in num_parent)\n",
    "    \n",
    "    best_idx, best_thr = None, None\n",
    "    \n",
    "    for i in range depth:\n",
    "        \n",
    "        # loop all the feature\n",
    "        for idx in range(data.iloc[:,:3]):\n",
    "\n",
    "            thresholds, classes = zip(*sorted(zip(data.iloc[:,idx], data['class'])))\n",
    "\n",
    "            num_left = [0] * data['class']\n",
    "            num_right = num_parent.copy()\n",
    "\n",
    "            for i in range(1,m):\n",
    "                c = classes[i-1]\n",
    "                num_left[c] += 1\n",
    "                num_right[c] -= 1\n",
    "\n",
    "                # count the gini index of left tree\n",
    "                gini_left = 1.0 - sum((num_left[x] / i) ** 2 for x in range(len(set(list(data['class'])))))\n",
    "\n",
    "                # count the gini index of right tree\n",
    "                gini_right = 1.0 - sum((num_right[x] / (m - i)) ** 2 for x in range(len(set(list(data['class'])))))\n",
    "\n",
    "                # gini impurity of a split is the weighted average of Gini\n",
    "                gini = (i * gini_left + (m - i) * gini_right) / m\n",
    "\n",
    "                if thresholds[i] == thresholds[i - 1]:\n",
    "                        continue\n",
    "\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_idx = idx\n",
    "                    best_thr = (thresholds[i] + thresholds[i - 1]) / 2  # midpoint\n",
    "\n",
    "        return best_idx, best_thr\n",
    "\n",
    "    \n",
    "# if the function works, we can use accuracy_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13ddb1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a4f73930",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,:3]\n",
    "y = df['class']\n",
    "model = DecisionTreeClassifier(criterion='gini',max_depth=3)\n",
    "\n",
    "clf = model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7999df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "16ca2f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** Tree Summary ***************\n",
      "Classes:  [1 2]\n",
      "Tree Depth:  3\n",
      "No. of leaves:  6\n",
      "No. of features:  3\n",
      "--------------------------------------------------------\n",
      "\n",
      "*************** Evaluation on Data ***************\n",
      "Accuracy Score:  0.9996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00      1249\n",
      "           2       1.00      1.00      1.00      1251\n",
      "\n",
      "    accuracy                           1.00      2500\n",
      "   macro avg       1.00      1.00      1.00      2500\n",
      "weighted avg       1.00      1.00      1.00      2500\n",
      "\n",
      "--------------------------------------------------------\n",
      "\n",
      "Accuracy: 0.9996\n"
     ]
    }
   ],
   "source": [
    "print('*************** Tree Summary ***************')\n",
    "print('Classes: ', clf.classes_)\n",
    "print('Tree Depth: ', clf.tree_.max_depth)\n",
    "print('No. of leaves: ', clf.tree_.n_leaves)\n",
    "print('No. of features: ', clf.n_features_)\n",
    "print('--------------------------------------------------------')\n",
    "print(\"\")\n",
    "\n",
    "print('*************** Evaluation on Data ***************')\n",
    "score = model.score(X, y)\n",
    "predict = model.predict(X)\n",
    "print('Accuracy Score: ', score)\n",
    "# Look at classification report to evaluate the model\n",
    "print(classification_report(y, predict))\n",
    "print('--------------------------------------------------------')\n",
    "print(\"\")\n",
    "print(\"Accuracy:\",accuracy_score(y, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f9a682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8446cae2",
   "metadata": {},
   "source": [
    "### Question 2: Random Forest Classifier\n",
    "- A simle RF implementation (10 pts)\n",
    "    - make a bootstrap baggin function to make 3 samples.\n",
    "    - for each sample, run a simple DT from question 1.\n",
    "    - then average the accuracy. \n",
    "- Classification using RandomForestClassifier (5 pts)\n",
    "- Evaluation (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94766822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the method of selecting feature in the all features to number of log(all_features)\n",
    "\n",
    "rand_tree=[]\n",
    "\n",
    "\n",
    "def my_RFC (number_trees,data):\n",
    "    features_len=data['class'].size \n",
    "    for i in range(number_trees):\n",
    "        # for boostrap, randomly select the features \n",
    "        indices = np.random.permutation(features_len)[:max(1,int(log2(features_len)))]\n",
    "        \n",
    "        # if the decisiontree function work,..from question 1\n",
    "        cart_tree = MyDecisitionTree(data.iloc[:,:3][indices],depth)\n",
    "        rand_tree.append(copy(cart_tree))\n",
    "        \n",
    "# if the function works, we can use accuracy_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a14ee50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(n_estimators=100,max_samples=3)\n",
    "\n",
    "clf.fit(X,y)\n",
    "y_pred=clf.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a3370ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c    0.375000\n",
       "a    0.323718\n",
       "b    0.301282\n",
       "dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to find the most important features\n",
    "feature_imp = pd.Series(clf.feature_importances_,index=['a','b','c']).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a311d522",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "788a1011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** Evaluation on Data ***************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.99      0.96      1249\n",
      "           2       0.99      0.93      0.96      1251\n",
      "\n",
      "    accuracy                           0.96      2500\n",
      "   macro avg       0.96      0.96      0.96      2500\n",
      "weighted avg       0.97      0.96      0.96      2500\n",
      "\n",
      "--------------------------------------------------------\n",
      "\n",
      "Accuracy: 0.9632\n"
     ]
    }
   ],
   "source": [
    "print('*************** Evaluation on Data ***************')\n",
    "score = clf.score(X, y)\n",
    "predict = clf.predict(X)\n",
    "\n",
    "# Look at classification report to evaluate the model\n",
    "print(classification_report(y, predict))\n",
    "print('--------------------------------------------------------')\n",
    "print(\"\")\n",
    "print(\"Accuracy:\",accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0454df6",
   "metadata": {},
   "source": [
    "### Question 3: AdaBoost Classifier\n",
    "- AB implementation (15 pts)\n",
    "- Classification using AdaBoostClassifier (5 pts)\n",
    "- Evaluation (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6044fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly, we are going to set a based decision tree function as decision stump\n",
    "\n",
    "def decisionTree(data,sample_weight):\n",
    "    # the shape of dataset\n",
    "    n=data.shape[1]\n",
    "    \n",
    "    for i in range(n):\n",
    "        feature = data[:,i] \n",
    "        \n",
    "        feature_unique = np.sort(np.unique(feature)) # sort the feature \n",
    "        \n",
    "        for j in range(len(feature_unique)):\n",
    "            # setting the threshold value\n",
    "            threshold = (feature_unique[j] + feature_unique[j+1])/2\n",
    "            \n",
    "            # to distinguish what threshold as the true features \n",
    "            for z in (0,1):\n",
    "                if z==1:\n",
    "                    y = 2*(feature>= threshold)-1\n",
    "                else:\n",
    "                    y =2*(feature < threshold)-1\n",
    "                err = np.sum((y != y)*sample_weight) \n",
    "                \n",
    "    return err\n",
    "\n",
    "\n",
    "#Secondly, to set a AdaBoostClassifier\n",
    "\n",
    "estimators =[]\n",
    "alphas = []\n",
    "def my_adaboost(data,n_estimators=100):\n",
    "    \n",
    "    sample_weight = np.ones(len(data))/len(data) # initialize the sample as 1/N\n",
    "    \n",
    "    for i in range(n_estimators):\n",
    "        # dc is from decisionTree() \n",
    "        dc = decisionTree(data,sample_weight) #dc return an error\n",
    "        \n",
    "        alpha = 1/2 *np.log((1-dc)/dc) # the weight of the lastest estimator\n",
    "        \n",
    "        y_pred = dc.predict(data)# Sorry, I do not set the predict function\n",
    "        #,but something like if the feature is true, then 2*(feature >= best_threshold)-1 \n",
    "        # else 2*(feature >= best_threshold)-1\n",
    "        \n",
    "        sample_weight *= np.exp(-alpha*y_pred*y) \n",
    "        \n",
    "        sample_weight /= np.sum(sample_weight) # sum all the estimators\n",
    "        \n",
    "        estimators.append(dc)\n",
    "        alpha.append(alpha)\n",
    "        \n",
    "    return estimators,alpha\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ffabffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ada_model = AdaBoostClassifier(n_estimators=50,learning_rate=1)\n",
    "Ada_model.fit(X,y)\n",
    "\n",
    "y_pred = model.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6970aaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** Evaluation on Data ***************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00      1249\n",
      "           2       1.00      1.00      1.00      1251\n",
      "\n",
      "    accuracy                           1.00      2500\n",
      "   macro avg       1.00      1.00      1.00      2500\n",
      "weighted avg       1.00      1.00      1.00      2500\n",
      "\n",
      "--------------------------------------------------------\n",
      "\n",
      "Accuracy: 0.9996\n"
     ]
    }
   ],
   "source": [
    "print('*************** Evaluation on Data ***************')\n",
    "score = Ada_model.score(X, y)\n",
    "predict = Ada_model.predict(X)\n",
    "\n",
    "# Look at classification report to evaluate the model\n",
    "print(classification_report(y, predict))\n",
    "print('--------------------------------------------------------')\n",
    "print(\"\")\n",
    "print(\"Accuracy:\",accuracy_score(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e0b530",
   "metadata": {},
   "source": [
    "### Question 4: Gradient Boost Classifier\n",
    "- GB implementation (15 pts)\n",
    "- Classification using GradientBoostingClassifier (5 pts)\n",
    "- Evaluation (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beea6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretend we have regeressiontree, as for classification we need to count residual \n",
    "\n",
    "def my_gradient_boost(data,n_estimators):\n",
    "    \n",
    "    regression_tree.fit(data.iloc[:,:3],data['class'])\n",
    "    y_pred = regerssion.predict(data.iloc[:,:3],data['class'])\n",
    "    \n",
    "    for i in range(n_estimators):\n",
    "        \n",
    "        gradient = loss.gradient(y,y_pred)\n",
    "        regerssion_tree[i].fit(data.iloc[:,:3],gradient) # for loop is for the next tree to fit the tree before it\n",
    "        \n",
    "        y_ pred -=np.multiply(learning_rate,regerssion_tree[i].predict(data.iloc[:,:3]) )\n",
    "        \n",
    "        # to cauclate the sum the residual and max probability of y_pred\n",
    "        y_pred = np.exp(y_pred)/np.expand_dims(np.sum(np.exp(y_pred), axis=1), axis=1)\n",
    "        y_pred = np.argmax(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8043c714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.5, random_state=0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBC = GradientBoostingClassifier(n_estimators=100, learning_rate=0.5,max_depth=3, random_state=0)\n",
    "GBC.fit(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c8971fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** Evaluation on Data ***************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00      1249\n",
      "           2       1.00      1.00      1.00      1251\n",
      "\n",
      "    accuracy                           1.00      2500\n",
      "   macro avg       1.00      1.00      1.00      2500\n",
      "weighted avg       1.00      1.00      1.00      2500\n",
      "\n",
      "--------------------------------------------------------\n",
      "\n",
      "Accuracy: 0.9996\n"
     ]
    }
   ],
   "source": [
    "print('*************** Evaluation on Data ***************')\n",
    "score = GBC.score(X, y)\n",
    "predict = GBC.predict(X)\n",
    "\n",
    "# Look at classification report to evaluate the model\n",
    "print(classification_report(y, predict))\n",
    "print('--------------------------------------------------------')\n",
    "print(\"\")\n",
    "print(\"Accuracy:\",accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d1c538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
